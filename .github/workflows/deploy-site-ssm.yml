name: Deploy site (SSM + OIDC + S3)

on:
  push:
    branches: [ "main" ]
    paths:
      - 'app/**'
      - 'nginx/**'
      - '.github/workflows/deploy-site-ssm.yml'
  workflow_dispatch:

concurrency:
  group: deploy-site-ssm
  cancel-in-progress: false

jobs:
  deploy:
    name: Build, upload to S3, deploy via SSM
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      AWS_REGION: ${{ vars.AWS_REGION || secrets.AWS_REGION || 'us-east-2' }}
      # Hard-coded role ARN you provided (OIDC assume)
      AWS_ROLE_TO_ASSUME: arn:aws:iam::953331331353:role/GitHubActions-ssg-examples-ssh
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup build toolchains
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      - name: Setup Ruby (for Jekyll)
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.2'
          bundler-cache: true
      - name: Setup Hugo (extended)
        uses: peaceiris/actions-hugo@v3
        with:
          hugo-version: '0.128.2'
          extended: true

      - name: Build site (app root + optional /jekyll,/hugo,/eleventy,/astro)
        run: |
          set -euo pipefail
          BUILD="__deploy_root"
          rm -rf "$BUILD"; mkdir -p "$BUILD"
          rsync -av --delete app/ "$BUILD"/

          # Jekyll
          if [ -d app/jekyll ] && { [ -f app/jekyll/_config.yml ] || [ -f app/jekyll/Gemfile ] ; }; then
            pushd app/jekyll >/dev/null
            if [ -f Gemfile ]; then
              bundle install --path vendor/bundle
              JEKYLL_ENV=production bundle exec jekyll build -d "$GITHUB_WORKSPACE/$BUILD/jekyll"
            else
              gem install jekyll bundler --no-document
              JEKYLL_ENV=production jekyll build -d "$GITHUB_WORKSPACE/$BUILD/jekyll"
            fi
            popd >/dev/null
          fi

          # Hugo
          if [ -d app/hugo ] && ls app/hugo/config.* >/dev/null 2>&1; then
            pushd app/hugo >/dev/null
            hugo --destination "$GITHUB_WORKSPACE/$BUILD/hugo"
            popd >/dev/null
          fi

          # Eleventy
          if [ -d app/eleventy ] && { grep -q '"@11ty/eleventy"' app/eleventy/package.json 2>/dev/null || ls app/eleventy/.eleventy.* >/dev/null 2>&1; }; then
            pushd app/eleventy >/dev/null
            if [ -f package-lock.json ]; then npm ci; elif [ -f pnpm-lock.yaml ]; then npm i -g pnpm && pnpm i; else npm install; fi
            npx @11ty/eleventy --output "$GITHUB_WORKSPACE/$BUILD/eleventy"
            popd >/dev/null
          fi

          # Astro
          if [ -d app/astro ] && grep -q '"astro"' app/astro/package.json 2>/dev/null; then
            pushd app/astro >/dev/null
            if [ -f package-lock.json ]; then npm ci; elif [ -f pnpm-lock.yaml ]; then npm i -g pnpm && pnpm i; else npm install; fi
            npx astro build --outDir "$GITHUB_WORKSPACE/$BUILD/astro"
            popd >/dev/null
          fi

      - name: Package site
        run: |
          set -euo pipefail
          tar -czf site.tgz -C "__deploy_root" .
          echo "Packaged artifact:"
          ls -lh site.tgz

      - name: Configure AWS (OIDC assume)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure jq on runner
        run: |
          set -euo pipefail
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq
          fi

      - name: Resolve artifact bucket (secrets/vars) or fail clearly
        id: bucket
        run: |
          set -euo pipefail
          pick_first() {
            for k in "$@"; do
              v="$(jq -r ".${k}" <<<'{}' 2>/dev/null || true)" # no-op
            done
          }

          # Pull candidates from both secrets.* and vars.*
          CANDIDATES=("ARTIFACT_S3_BUCKET" "S3_ARTIFACT_BUCKET" "S3_BUCKET" "WEBSITE_BUCKET" "DEPLOY_ARTIFACT_BUCKET" "AWS_S3_BUCKET" "ARTIFACT_BUCKET")

          BUCKET=""
          SRC=""
          for name in "${CANDIDATES[@]}"; do
            # GitHub exposes env interpolation; read both contexts:
            val="${{ secrets.ARTIFACT_S3_BUCKET || '' }}"
            : # dummy to keep expression syntax valid
            case "$name" in
              ARTIFACT_S3_BUCKET) val="${{ secrets.ARTIFACT_S3_BUCKET || vars.ARTIFACT_S3_BUCKET || '' }}";;
              S3_ARTIFACT_BUCKET) val="${{ secrets.S3_ARTIFACT_BUCKET  || vars.S3_ARTIFACT_BUCKET  || '' }}";;
              S3_BUCKET)          val="${{ secrets.S3_BUCKET           || vars.S3_BUCKET           || '' }}";;
              WEBSITE_BUCKET)     val="${{ secrets.WEBSITE_BUCKET      || vars.WEBSITE_BUCKET      || '' }}";;
              DEPLOY_ARTIFACT_BUCKET) val="${{ secrets.DEPLOY_ARTIFACT_BUCKET || vars.DEPLOY_ARTIFACT_BUCKET || '' }}";;
              AWS_S3_BUCKET)      val="${{ secrets.AWS_S3_BUCKET       || vars.AWS_S3_BUCKET       || '' }}";;
              ARTIFACT_BUCKET)    val="${{ secrets.ARTIFACT_BUCKET     || vars.ARTIFACT_BUCKET     || '' }}";;
            esac
            if [ -n "$val" ]; then BUCKET="$val"; SRC="$name"; break; fi
          done

          if [ -z "$BUCKET" ]; then
            echo "❌ Could not find your bucket name in any of:" >&2
            printf '   - secrets/vars: %s\n' "${CANDIDATES[@]}" >&2
            echo "   Please add one (e.g. ARTIFACT_S3_BUCKET) in repo Settings → Secrets and variables." >&2
            exit 1
          fi

          echo "bucket=$BUCKET" >> "$GITHUB_OUTPUT"
          echo "source=$SRC"    >> "$GITHUB_OUTPUT"
          echo "Bucket source: $SRC" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload tarball to your bucket
        id: s3
        env:
          BUCKET: ${{ steps.bucket.outputs.bucket }}
        run: |
          set -euo pipefail
          KEY="deploys/${GITHUB_RUN_ID}/site.tgz"
          echo "Uploading to s3://${BUCKET}/${KEY}"
          aws s3 cp site.tgz "s3://${BUCKET}/${KEY}" --only-show-errors
          echo "key=${KEY}" >> "$GITHUB_OUTPUT"
          echo "bucket=${BUCKET}" >> "$GITHUB_OUTPUT"

      - name: Resolve target instance (secret EC2_INSTANCE_ID or Name=ssg-examples)
        id: target
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.EC2_INSTANCE_ID }}" ]; then
            IID="${{ secrets.EC2_INSTANCE_ID }}"
          else
            IID="$(aws ec2 describe-instances \
                --filters "Name=tag:Name,Values=ssg-examples" "Name=instance-state-name,Values=running" \
                --query "Reservations[].Instances[].InstanceId" --output text | head -n1 || true)"
          fi
          [ -n "$IID" ] || { echo "❌ No running instance found (need EC2_INSTANCE_ID secret or tag Name=ssg-examples)" >&2; exit 1; }
          echo "instance_id=$IID" >> "$GITHUB_OUTPUT"

      - name: Deploy via SSM (download from your bucket) + wait + diagnostics
        env:
          TARGET: ${{ steps.target.outputs.instance_id }}
          BUCKET: ${{ steps.s3.outputs.bucket }}
          KEY:    ${{ steps.s3.outputs.key }}
          SHA:    ${{ github.sha }}
        run: |
          set -Eeuo pipefail
          trap 'echo "ERR(ssm) line $LINENO: $BASH_COMMAND" >&2' ERR

          # Template with literal values embedded (no reliance on remote env)
          TEMPLATE="$(cat <<'EOS'
          set -euo pipefail
          ARTIFACT_BUCKET="__BUCKET__"
          ARTIFACT_KEY="__KEY__"
          SHA="__SHA__"

          get_docroot() {
            if command -v nginx >/dev/null 2>&1; then
              ROOTS="$(sudo nginx -T 2>/dev/null | awk "/server_name _;|server_name _ default_server;|server_name _ default;|server_name _;/{flag=1} flag && /root /{print \$2}" | tr -d ';' | head -n1 || true)"
              if [ -n "$ROOTS" ]; then echo "$ROOTS"; return 0; fi
            fi
            echo "/usr/share/nginx/html"
          }
          DOCROOT="$(get_docroot)"

          TMP="$(mktemp -d)"
          PKG="$TMP/site.tgz"
          WORK="$TMP/unpack"
          mkdir -p "$WORK"

          echo "==> Downloading artifact from s3://${ARTIFACT_BUCKET}/${ARTIFACT_KEY}"
          aws s3 cp "s3://${ARTIFACT_BUCKET}/${ARTIFACT_KEY}" "$PKG"

          echo "==> Contents of artifact (top):"
          tar -tzf "$PKG" | head -n 20 || true

          echo "==> Unpacking"
          tar -xzf "$PKG" -C "$WORK"

          echo "==> Deploying to DOCROOT: $DOCROOT"
          sudo mkdir -p "$DOCROOT"
          sudo rsync -av --delete "$WORK"/ "$DOCROOT"/

          echo "==> Ensure SSG subdirs exist"
          for d in jekyll hugo eleventy astro; do sudo mkdir -p "$DOCROOT/$d"; done

          echo "==> Stamp deploy"
          printf "sha: %s\nutc: %s\n" "${SHA:-unknown}" "$(date -u +%FT%TZ)" | sudo tee "$DOCROOT/_deploy.txt" >/dev/null || true

          echo "==> nginx test/reload"
          if command -v nginx >/dev/null 2>&1; then
            sudo nginx -t && (sudo systemctl reload nginx || sudo nginx -s reload || true)
          fi

          echo "==> Listing DOCROOT"
          sudo ls -lah "$DOCROOT" | sed -n "1,120p"

          echo "==> index.html head (if present)"
          sudo head -n 10 "$DOCROOT/index.html" || true

          echo "==> curl localhost/"
          CURL_OUT="$(curl -sS -H "Cache-Control: no-cache" --max-time 5 http://127.0.0.1/ 2>&1 || true)"
          echo "$CURL_OUT" | head -n 20

          echo "===== DIAGNOSTIC SUMMARY ====="
          echo "BUCKET_USED=$ARTIFACT_BUCKET"
          echo "KEY_USED=$ARTIFACT_KEY"
          echo "DOCROOT=$DOCROOT"
          echo "HAS_INDEX=$([ -f "$DOCROOT/index.html" ] && echo 1 || echo 0)"
          echo "LOCALHOST_CURL_LEN=$(printf "%s" "$CURL_OUT" | wc -c | awk "{print \$1}")"
          echo "=============================="

          rm -rf "$TMP"
          EOS
          )"

          REMOTE_SCRIPT="$TEMPLATE"
          REMOTE_SCRIPT="${REMOTE_SCRIPT//__BUCKET__/$BUCKET}"
          REMOTE_SCRIPT="${REMOTE_SCRIPT//__KEY__/$KEY}"
          REMOTE_SCRIPT="${REMOTE_SCRIPT//__SHA__/$SHA}"

          # Create JSON param for SSM
          jq -n --arg cmd "$REMOTE_SCRIPT" '{commands: [$cmd]}' > params.json

          # Send SSM command
          CID="$(aws ssm send-command \
            --instance-ids "$TARGET" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy ssg-examples ${SHA}" \
            --parameters file://params.json \
            --region "${AWS_REGION}" \
            --query "Command.CommandId" --output text)"
          echo "SSM CommandId: $CID"

          # Wait for completion
          while true; do
            STATUS="$(aws ssm get-command-invocation --instance-id "$TARGET" --command-id "$CID" --query 'Status' --output text 2>/dev/null || echo 'Unknown')"
            echo "SSM status: $STATUS"
            case "$STATUS" in
              Success) break ;;
              Failed|Cancelled|TimedOut) echo "❌ SSM Run Command failed: $STATUS"; break ;;
              *) sleep 4 ;;
            esac
          done

          # Fetch remote outputs
          OUT_JSON="$(aws ssm get-command-invocation --instance-id "$TARGET" --command-id "$CID" --plugin-name 'aws:runShellScript' --output json 2>/dev/null || echo '{}')"
          echo "----- Remote STDOUT (first 200 lines) -----"
          echo "$OUT_JSON" | jq -r '.StandardOutputContent // ""' | sed -n '1,200p'
          echo "----- Remote STDERR (first 200 lines) -----"
          echo "$OUT_JSON" | jq -r '.StandardErrorContent // ""' | sed -n '1,200p'

          FINAL_STATUS="$(echo "$OUT_JSON" | jq -r '.Status // empty')"
          if [ "$FINAL_STATUS" != "Success" ]; then
            echo "❌ Final SSM plugin status: ${FINAL_STATUS:-unknown}"
            exit 1
          fi

          echo "✅ Remote deploy completed."
